{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Liger Simulations V1-C.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YKYKzIk0coAS"
      },
      "source": [
        "## (A) Neural Matrix Factorizarion Steps -  NeuMF Paper\n",
        "\n",
        "1.   Usually given an \"object 1 by object 2\" observation matrix M with explicit feedback data.\n",
        "\n",
        "---\n",
        "\n",
        "2.   Two learning approaches can be adopted: \n",
        "\n",
        "*   Pointwise learning: follows a regression framework by minimizing the squred loss between *yPredicted* and *yObserved*.\n",
        "*   Pairwise learning: this ranks observed entries higher relative to unobserved entries, and maximizes the margin between them.\n",
        "\n",
        "---\n",
        "\n",
        "3. Electing pointwise learning, the training phase involves searching for the optimal parameters that minimizes this squared loss over a reduced (k-dimensional) feature space.\n",
        "\n",
        "---\n",
        "\n",
        "*   Predictions can then be made for the unobserved entries.\n",
        "*   In essence, both the observed and unobserved entries have been approximated by a non-linear function, which presumably improves upon linear(dot product) approximation.\n",
        "\n",
        "---\n",
        "\n",
        "What's often done(and adopted by the paper) is to restructure the problem to make use of implicit data (more easy to collect compared to explicit data)\n",
        "\n",
        "So in this case, the observation matrix M is converted into a binary interaction matrix P. The training prediction processes are similar as in the case of learning with M.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "## (B) Recovering the gene expression matrix(normalized) from LIGER ##\n",
        "\n",
        "1. Pass the downsampled control and interferon-stimulated PBMCs to the LIGER function.\n",
        "\n",
        "2. The LIGER function returns a normalized **H1, H2**, **V1, V2**, and **W**(shared) by performing non-negative matrix factorization.\n",
        "\n",
        "3. These matrices can be used to recover a dense representation of the original expression matrices.\n",
        "\n",
        "4. ** The \"cell paper\" then achieves integrative clustering by buildng a shared neighbourhood graph following the five steps of \"Joint clustering and factor normalization\" under the STAR methods.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "## (C) Self Implementation\n",
        "\n",
        "### Get data:\n",
        "1. A first option to getting the gene expression matrices is to recover them from the LIGER output.\n",
        "\n",
        "\n",
        "\n",
        "  *   The recovered matrices are a dense representation of the original expression matrices\n",
        "  *  Once the data is obtained this way, NeuMF cannot be applied for the simple reason that there are presumably no negative(unobserved/missing) instances.\n",
        "\n",
        "2. A second option will be to get the raw representation. This option will allow the application of NeuMF.\n",
        "\n",
        "---\n",
        "### Implementation Steps:\n",
        "\n",
        "1. Create a LIGER object with the raw data (stim & ctrl datasets)\n",
        "  -  This allows the recovery of a sparse gene by cell matrix.\n",
        "  - Cells not expressing any genes and genes not expressed in any cell are removed.\n",
        "  - Any remaining 0 is thus a \"true\" missing expression.\n",
        "  - Two sparse matrix representations will result; \"ctr_sparse\" and \"stim_sparse\"\n",
        "\n",
        "2. Feed the two sparse representations separately through the network. \n",
        "  - This will produce two dense representations of the sparse versions.\n",
        "  - The NeuMF will leverage any existing non-linear relationship between the cells and genes whiles maintaining the usual linear operations for better predictions.\n",
        "\n",
        "3. Using these two dense representations create a LIGER object with placeholders for H1, H2, V1, V2 and the shared matrix W.\n",
        "\n",
        "4. Scale and normalize the values of the resulting object. This ensures each gene has the same variance and also accounts for varying sequencing depths.\n",
        "\n",
        "5. Run the NMF algorithm from LIGER to get values for the matrices in (3)\n",
        "\n",
        "6. Build the shared neighbourhood graph and carry out the clustering. Implementation can be done with the LIGER package.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "## (D) Why this gives better clusters\n",
        "\n",
        "    ** will denote the paper implementation\n",
        "    *** will denote the corresponding implemntation in NeuMF\n",
        "---\n",
        "\n",
        "1. ### Factorization Method:\n",
        "\n",
        "---\n",
        "  ** -- Finds the matrices (of reduced dimensions) in (C)(3) by minimizing the penealized frobenius norm squared error between the observed and estimated matrices.\n",
        "\n",
        "  *** -- Finds some two lower dimensional matrics say U & V, that densely approximates the observed expression matrix by minimizing the MSE.\n",
        "\n",
        "  * The two loss functions are similar and differ only by a transformation.\n",
        "\n",
        "---\n",
        "\n",
        "2. ### Optimization Algorithm:\n",
        "\n",
        "---\n",
        "\n",
        "  **  -- Uses Block Cordinate Descent. It iteratively minimizes the factorization objective by making use of profiling. Convergence (local min) is guaranteed.\n",
        "\n",
        "  *** -- Uses Stochastic Gradient Descent. Simultaneously update model network parameters to minimze the loss function. Convergence is not guaranteed but saddle points in deep networks have shown to produce optimal functions than their shallow counterparts (BCD can be formulated as such).\n",
        "\n",
        "---\n",
        "\n",
        "3. ### Prediction Function:\n",
        "\n",
        "---\n",
        "\n",
        "  **  -- Basically a linear approximation.\n",
        "\n",
        "  *** -- Introduces non-linearities via the activation fucntions.\n",
        "\n",
        "---\n",
        "\n",
        "* For any cell gene expression matrix, NeuMF will always perform atleast as well as NMF Liger implementation. Performance will be indistninguishable if only linear (unlikely) relationship is present.\n",
        "\n",
        "* For the same factor specification k, performing Liger NMF on a dense output from NeuMF will not have any impact.\n",
        "\n",
        "* The above is why it makes sense to create a LIGER object with the matrices from NeuMF and cluster based on LIGERs NNB implementation.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pKq2U_eCm4Vz"
      },
      "source": [
        "## **Code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cG9sxo1PcVRh",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e73eca9b-2eb1-4cb9-bdf7-5efb9c68e80f"
      },
      "source": [
        "# load packages\n",
        "import csv\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import scipy as sc\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import urllib.request as urllib\n",
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "from sklearn.manifold import TSNE\n",
        "import sklearn.cluster as cluster\n",
        "from sklearn.utils import shuffle\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDuenTEC1e7V",
        "colab_type": "text"
      },
      "source": [
        "### Test connections to TPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfjI1SvC1h1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "f4c40498-a8ad-4d86-e480-5599007120fd"
      },
      "source": [
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0\n",
            "Running on TPU  ['10.83.219.186:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.83.219.186:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.83.219.186:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IDREwBw_nVIz"
      },
      "source": [
        "## **(1) Load and Process Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eu4v8rZD_0v0",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# load data\n",
        "url = 'https://sixtusdakurah.com/projects/liger/ctrl_sparse_dfp.csv'\n",
        "ctrl_sparse = pd.read_csv(url, sep=\",\", header=0)\n",
        "ctrl_sparse = ctrl_sparse.rename(columns={'Unnamed: 0': 'gene'})"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DXU4LaYfBUvk",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "3fa27fcc-b7c1-4ff5-bdf2-1fbb0b03a7a3"
      },
      "source": [
        "# check dimensions and get brief view\n",
        "ctrl_sparse.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gene</th>\n",
              "      <th>ctrlTCAGCGCTGGTCAT-1</th>\n",
              "      <th>ctrlTTATGGCTTCATTC-1</th>\n",
              "      <th>ctrlACCCACTGCTTAGG-1</th>\n",
              "      <th>ctrlATGGGTACCCCGTT-1</th>\n",
              "      <th>ctrlTGACTGGACAGTCA-1</th>\n",
              "      <th>ctrlGTGTAGTGGTTGTG-1</th>\n",
              "      <th>ctrlTGCGAAACGCATCA-1</th>\n",
              "      <th>ctrlTTCAACACTGAGGG-1</th>\n",
              "      <th>ctrlATTACCACGAATGA-1</th>\n",
              "      <th>ctrlACGCCACTTCTTTG-1</th>\n",
              "      <th>ctrlTAAGATTGAGTCAC-1</th>\n",
              "      <th>ctrlGACGCCGATTACCT-1</th>\n",
              "      <th>ctrlCTGATTTGACTAGC-1</th>\n",
              "      <th>ctrlCTACTCCTTGAGAA-1</th>\n",
              "      <th>ctrlATGTCGGATCACCC-1</th>\n",
              "      <th>ctrlATGGACACTGGGAG-1</th>\n",
              "      <th>ctrlCTGACAGAACTACG-1</th>\n",
              "      <th>ctrlAACTTGCTGGTGGA-1</th>\n",
              "      <th>ctrlAACAGAGACGTTGA-1</th>\n",
              "      <th>ctrlCATCGGCTATGTGC-1</th>\n",
              "      <th>ctrlTCTCTAGAACTTTC-1</th>\n",
              "      <th>ctrlCCACCTGAATACCG-1</th>\n",
              "      <th>ctrlTACTACTGGGCGAA-1</th>\n",
              "      <th>ctrlGCACACCTCTGTCC-1</th>\n",
              "      <th>ctrlGCTCAGCTAAACAG-1</th>\n",
              "      <th>ctrlTGCATGGAACGGTT-1</th>\n",
              "      <th>ctrlAAGGCTACTCTATC-1</th>\n",
              "      <th>ctrlGAAAGCCTTCTTAC-1</th>\n",
              "      <th>ctrlCGTTTAACGCTTCC-1</th>\n",
              "      <th>ctrlTCGGCACTGGTATC-1</th>\n",
              "      <th>ctrlCTTAGACTGTCATG-1</th>\n",
              "      <th>ctrlTACTCTGACAGAGG-1</th>\n",
              "      <th>ctrlCTATGTTGGGATCT-1</th>\n",
              "      <th>ctrlACCGAAACGTGTAC-1</th>\n",
              "      <th>ctrlACTACTACACACCA-1</th>\n",
              "      <th>ctrlGAGTGACTGTGAGG-1</th>\n",
              "      <th>ctrlAGTTATGAGTAAAG-1</th>\n",
              "      <th>ctrlATGCACGATCCGTC-1</th>\n",
              "      <th>ctrlGAAGGGTGTGTGGT-1</th>\n",
              "      <th>...</th>\n",
              "      <th>ctrlGACGCCGAGCTGTA-1</th>\n",
              "      <th>ctrlGAGTACACCTGTGA-1</th>\n",
              "      <th>ctrlGTTCAACTACTGTG-1</th>\n",
              "      <th>ctrlTGATCACTATCGGT-1</th>\n",
              "      <th>ctrlGCTACAGATTCGTT-1</th>\n",
              "      <th>ctrlCAGTCAGATGTCCC-1</th>\n",
              "      <th>ctrlCACAACGACACTGA-1</th>\n",
              "      <th>ctrlTATAGATGGTGCTA-1</th>\n",
              "      <th>ctrlGCATGATGTGTGCA-1</th>\n",
              "      <th>ctrlCTTACATGAGGAGC-1</th>\n",
              "      <th>ctrlAGCCGGTGCTGAGT-1</th>\n",
              "      <th>ctrlCGCAGGACAAAGCA-1</th>\n",
              "      <th>ctrlGAAGCTACCCATAG-1</th>\n",
              "      <th>ctrlCTGACCACTGAGCT-1</th>\n",
              "      <th>ctrlTACGAGTGTTATCC-1</th>\n",
              "      <th>ctrlAATCTAGATAGCGT-1</th>\n",
              "      <th>ctrlTCGGCACTCCCACT-1</th>\n",
              "      <th>ctrlCCAGAAACTTCGGA-1</th>\n",
              "      <th>ctrlTCATGTACGCTTAG-1</th>\n",
              "      <th>ctrlATCGCGCTGGGAGT-1</th>\n",
              "      <th>ctrlGAGAGGTGGAATCC-1</th>\n",
              "      <th>ctrlATTCTGACTGAGGG-1</th>\n",
              "      <th>ctrlGACAGGGAACTGTG-1</th>\n",
              "      <th>ctrlGAGGACGACGATAC-1</th>\n",
              "      <th>ctrlAATCTAGATTCTAC-1</th>\n",
              "      <th>ctrlTAGTATGAGTACCA-1</th>\n",
              "      <th>ctrlCATCGGCTACCTTT-1</th>\n",
              "      <th>ctrlGACCTCTGGCTGTA-1</th>\n",
              "      <th>ctrlAAGACAGAGAACCT-1</th>\n",
              "      <th>ctrlAAATCATGCTCTAT-1</th>\n",
              "      <th>ctrlGGCTACCTGCAGAG-1</th>\n",
              "      <th>ctrlGATATAACGAATAG-1</th>\n",
              "      <th>ctrlACAAATTGACCTGA-1</th>\n",
              "      <th>ctrlGAGATCACTGCCTC-1</th>\n",
              "      <th>ctrlGCCATGCTATGCCA-1</th>\n",
              "      <th>ctrlCAAGTTCTACGACT-1</th>\n",
              "      <th>ctrlACAGTGACCTTCGC-1</th>\n",
              "      <th>ctrlAATCTCACGTATCG-1</th>\n",
              "      <th>ctrlAGGTGGGACTCGCT-1</th>\n",
              "      <th>ctrlCCAACCTGGTATGC-1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RP11.206L10.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RP11.206L10.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LINC00115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FAM41C</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NOC2L</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 3001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            gene  ...  ctrlCCAACCTGGTATGC-1\n",
              "0  RP11.206L10.2  ...                     0\n",
              "1  RP11.206L10.9  ...                     0\n",
              "2      LINC00115  ...                     0\n",
              "3         FAM41C  ...                     0\n",
              "4          NOC2L  ...                     0\n",
              "\n",
              "[5 rows x 3001 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eIe3xYHSKHFR",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a37f12d-2e8d-4df1-ac3a-0bdadfcb548f"
      },
      "source": [
        "print(\"Shape of Ctrl: \", ctrl_sparse.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Ctrl:  (14879, 3001)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VeKqZb4XKlTj",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "ctr_E_df = ctrl_sparse#.iloc[0:10000, 0:3001]\n",
        "# convert to long format\n",
        "ctr_E_df_long = pd.melt(ctr_E_df, id_vars=['gene'],var_name='cell', value_name='expression')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_LCsLD3nK_tf",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "c56954c0-7119-481b-c2be-0a6b46d3a1d5"
      },
      "source": [
        "ctr_E_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gene</th>\n",
              "      <th>ctrlTCAGCGCTGGTCAT-1</th>\n",
              "      <th>ctrlTTATGGCTTCATTC-1</th>\n",
              "      <th>ctrlACCCACTGCTTAGG-1</th>\n",
              "      <th>ctrlATGGGTACCCCGTT-1</th>\n",
              "      <th>ctrlTGACTGGACAGTCA-1</th>\n",
              "      <th>ctrlGTGTAGTGGTTGTG-1</th>\n",
              "      <th>ctrlTGCGAAACGCATCA-1</th>\n",
              "      <th>ctrlTTCAACACTGAGGG-1</th>\n",
              "      <th>ctrlATTACCACGAATGA-1</th>\n",
              "      <th>ctrlACGCCACTTCTTTG-1</th>\n",
              "      <th>ctrlTAAGATTGAGTCAC-1</th>\n",
              "      <th>ctrlGACGCCGATTACCT-1</th>\n",
              "      <th>ctrlCTGATTTGACTAGC-1</th>\n",
              "      <th>ctrlCTACTCCTTGAGAA-1</th>\n",
              "      <th>ctrlATGTCGGATCACCC-1</th>\n",
              "      <th>ctrlATGGACACTGGGAG-1</th>\n",
              "      <th>ctrlCTGACAGAACTACG-1</th>\n",
              "      <th>ctrlAACTTGCTGGTGGA-1</th>\n",
              "      <th>ctrlAACAGAGACGTTGA-1</th>\n",
              "      <th>ctrlCATCGGCTATGTGC-1</th>\n",
              "      <th>ctrlTCTCTAGAACTTTC-1</th>\n",
              "      <th>ctrlCCACCTGAATACCG-1</th>\n",
              "      <th>ctrlTACTACTGGGCGAA-1</th>\n",
              "      <th>ctrlGCACACCTCTGTCC-1</th>\n",
              "      <th>ctrlGCTCAGCTAAACAG-1</th>\n",
              "      <th>ctrlTGCATGGAACGGTT-1</th>\n",
              "      <th>ctrlAAGGCTACTCTATC-1</th>\n",
              "      <th>ctrlGAAAGCCTTCTTAC-1</th>\n",
              "      <th>ctrlCGTTTAACGCTTCC-1</th>\n",
              "      <th>ctrlTCGGCACTGGTATC-1</th>\n",
              "      <th>ctrlCTTAGACTGTCATG-1</th>\n",
              "      <th>ctrlTACTCTGACAGAGG-1</th>\n",
              "      <th>ctrlCTATGTTGGGATCT-1</th>\n",
              "      <th>ctrlACCGAAACGTGTAC-1</th>\n",
              "      <th>ctrlACTACTACACACCA-1</th>\n",
              "      <th>ctrlGAGTGACTGTGAGG-1</th>\n",
              "      <th>ctrlAGTTATGAGTAAAG-1</th>\n",
              "      <th>ctrlATGCACGATCCGTC-1</th>\n",
              "      <th>ctrlGAAGGGTGTGTGGT-1</th>\n",
              "      <th>...</th>\n",
              "      <th>ctrlGACGCCGAGCTGTA-1</th>\n",
              "      <th>ctrlGAGTACACCTGTGA-1</th>\n",
              "      <th>ctrlGTTCAACTACTGTG-1</th>\n",
              "      <th>ctrlTGATCACTATCGGT-1</th>\n",
              "      <th>ctrlGCTACAGATTCGTT-1</th>\n",
              "      <th>ctrlCAGTCAGATGTCCC-1</th>\n",
              "      <th>ctrlCACAACGACACTGA-1</th>\n",
              "      <th>ctrlTATAGATGGTGCTA-1</th>\n",
              "      <th>ctrlGCATGATGTGTGCA-1</th>\n",
              "      <th>ctrlCTTACATGAGGAGC-1</th>\n",
              "      <th>ctrlAGCCGGTGCTGAGT-1</th>\n",
              "      <th>ctrlCGCAGGACAAAGCA-1</th>\n",
              "      <th>ctrlGAAGCTACCCATAG-1</th>\n",
              "      <th>ctrlCTGACCACTGAGCT-1</th>\n",
              "      <th>ctrlTACGAGTGTTATCC-1</th>\n",
              "      <th>ctrlAATCTAGATAGCGT-1</th>\n",
              "      <th>ctrlTCGGCACTCCCACT-1</th>\n",
              "      <th>ctrlCCAGAAACTTCGGA-1</th>\n",
              "      <th>ctrlTCATGTACGCTTAG-1</th>\n",
              "      <th>ctrlATCGCGCTGGGAGT-1</th>\n",
              "      <th>ctrlGAGAGGTGGAATCC-1</th>\n",
              "      <th>ctrlATTCTGACTGAGGG-1</th>\n",
              "      <th>ctrlGACAGGGAACTGTG-1</th>\n",
              "      <th>ctrlGAGGACGACGATAC-1</th>\n",
              "      <th>ctrlAATCTAGATTCTAC-1</th>\n",
              "      <th>ctrlTAGTATGAGTACCA-1</th>\n",
              "      <th>ctrlCATCGGCTACCTTT-1</th>\n",
              "      <th>ctrlGACCTCTGGCTGTA-1</th>\n",
              "      <th>ctrlAAGACAGAGAACCT-1</th>\n",
              "      <th>ctrlAAATCATGCTCTAT-1</th>\n",
              "      <th>ctrlGGCTACCTGCAGAG-1</th>\n",
              "      <th>ctrlGATATAACGAATAG-1</th>\n",
              "      <th>ctrlACAAATTGACCTGA-1</th>\n",
              "      <th>ctrlGAGATCACTGCCTC-1</th>\n",
              "      <th>ctrlGCCATGCTATGCCA-1</th>\n",
              "      <th>ctrlCAAGTTCTACGACT-1</th>\n",
              "      <th>ctrlACAGTGACCTTCGC-1</th>\n",
              "      <th>ctrlAATCTCACGTATCG-1</th>\n",
              "      <th>ctrlAGGTGGGACTCGCT-1</th>\n",
              "      <th>ctrlCCAACCTGGTATGC-1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RP11.206L10.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RP11.206L10.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LINC00115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FAM41C</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NOC2L</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 3001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            gene  ...  ctrlCCAACCTGGTATGC-1\n",
              "0  RP11.206L10.2  ...                     0\n",
              "1  RP11.206L10.9  ...                     0\n",
              "2      LINC00115  ...                     0\n",
              "3         FAM41C  ...                     0\n",
              "4          NOC2L  ...                     0\n",
              "\n",
              "[5 rows x 3001 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lkyMJunX3eQq",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "2585c88a-7b5c-47db-9cda-5513a87bb1f2"
      },
      "source": [
        "ctr_E_df_long.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gene</th>\n",
              "      <th>cell</th>\n",
              "      <th>expression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RP11.206L10.2</td>\n",
              "      <td>ctrlTCAGCGCTGGTCAT-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RP11.206L10.9</td>\n",
              "      <td>ctrlTCAGCGCTGGTCAT-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LINC00115</td>\n",
              "      <td>ctrlTCAGCGCTGGTCAT-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FAM41C</td>\n",
              "      <td>ctrlTCAGCGCTGGTCAT-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NOC2L</td>\n",
              "      <td>ctrlTCAGCGCTGGTCAT-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            gene                  cell  expression\n",
              "0  RP11.206L10.2  ctrlTCAGCGCTGGTCAT-1           0\n",
              "1  RP11.206L10.9  ctrlTCAGCGCTGGTCAT-1           0\n",
              "2      LINC00115  ctrlTCAGCGCTGGTCAT-1           0\n",
              "3         FAM41C  ctrlTCAGCGCTGGTCAT-1           0\n",
              "4          NOC2L  ctrlTCAGCGCTGGTCAT-1           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FS0xeH4nLKrW",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "668aa793-e68c-4831-a099-ae4c656e4eda"
      },
      "source": [
        "(ctr_E_df_long == 0).astype(int).sum(axis=0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gene                 0\n",
              "cell                 0\n",
              "expression    42839617\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pDYsclCeLY13",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "cd12d722-3f13-47b7-a480-49de02528a54"
      },
      "source": [
        "print(\"Unique genes: \", len((ctr_E_df_long['gene'].astype(\"category\").cat.codes).drop_duplicates()))#.sort_values()\n",
        "print(\"Unique cells: \",len((ctr_E_df_long['cell'].astype(\"category\").cat.codes).drop_duplicates()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique genes:  14879\n",
            "Unique cells:  3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YF77aCOvLmah"
      },
      "source": [
        "## **(2) Build Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "60_GURI7LqOS",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# process data set\n",
        "def process_dataset(df):\n",
        "\n",
        "    # Convert cells names into numerical IDs\n",
        "    df['cell_id'] = df['cell'].astype(\"category\").cat.codes\n",
        "    df['gene_id'] = df['gene'].astype(\"category\").cat.codes\n",
        "\n",
        "    \n",
        "    gene_lookup = df[['gene_id', 'gene']].drop_duplicates()\n",
        "    gene_lookup['gene_id'] = gene_lookup.gene_id.astype(str)\n",
        "\n",
        "    # Grab the columns we need in the order we need them.\n",
        "    df = df[['cell_id', 'gene_id', 'expression']]\n",
        "\n",
        "    \n",
        "    #df_train, df_test = train_test_split(df) # 80 20\n",
        "    df_train, df_test = df, ''\n",
        "\n",
        "\n",
        "    \n",
        "    cells = list(np.sort(df.cell_id.unique()))\n",
        "    genes = list(np.sort(df.gene_id.unique()))\n",
        "\n",
        "    \n",
        "    rows = df_train.cell_id.astype(int)\n",
        "    cols = df_train.gene_id.astype(int)\n",
        "\n",
        "    values = list(df_train.expression)\n",
        "\n",
        "    # Get all user ids and item ids.\n",
        "    cids = np.array(rows.tolist())\n",
        "    gids = np.array(cols.tolist())\n",
        "\n",
        "    # Sample 100 negative interactions for each cell in our test data\n",
        "    df_neg = '' #get_negatives(cids, gids, genes, df_test)\n",
        "\n",
        "    return cids, gids, df_train, df_test, df_neg, cells, genes, gene_lookup, values"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0OmveH4QLzkT",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# sample a couple of negatives for each positive label\n",
        "def get_negatives(cids, gids, genes, df_test):\n",
        "    \n",
        "    negativeList = []\n",
        "    test_c = df_test['cell_id'].values.tolist()\n",
        "    test_g = df_test['gene_id'].values.tolist()\n",
        "\n",
        "    test_expression_ids = list(zip(test_c, test_g))\n",
        "    zipped = set(zip(cids, gids))\n",
        "    #print(len(genes))\n",
        "\n",
        "    for (c, g) in test_expression_ids:\n",
        "        negatives = []\n",
        "        negatives.append((c, g))\n",
        "        for t in range(10):# increase for better accuracy\n",
        "            j = np.random.randint(len(genes)) # Get random gene id.\n",
        "            while (c, j) in zipped: # Check if there is an interaction\n",
        "                j = np.random.randint(len(genes)) # If yes, generate a new gene id\n",
        "            negatives.append(j) # Once a negative interaction is found we add it.\n",
        "            #print(\"J value is\", j)\n",
        "            #print(negatives)\n",
        "        negativeList.append(negatives)\n",
        "\n",
        "    df_neg = pd.DataFrame(negativeList)\n",
        "\n",
        "    return df_neg"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1yT-Sp8_MBAg",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# mask the first gene to be used for testing\n",
        "def mask_first(x):\n",
        "    result = np.ones_like(x)\n",
        "    result[0] = 0\n",
        "    \n",
        "    return result\n",
        "\n",
        "# split into train and test set   \n",
        "def train_test_split(df):\n",
        "\n",
        "    df_test = df.copy(deep=True)\n",
        "    df_train = df.copy(deep=True)\n",
        "\n",
        "    df_test = df_test.groupby(['cell_id']).first()\n",
        "    df_test['cell_id'] = df_test.index\n",
        "    df_test = df_test[['cell_id', 'gene_id', 'expression']]\n",
        "    df_test.index.name = None\n",
        "\n",
        "    mask = df.groupby(['cell_id'])['cell_id'].transform(mask_first).astype(bool)\n",
        "    df_train = df.loc[mask]\n",
        "\n",
        "    return df_train, df_test\n",
        "\n",
        "# combine mask and train test split\n",
        "def get_train_instances():\n",
        "    \n",
        "    cell_input, gene_input, labels = [],[],[]\n",
        "    zipped = set(zip(cids, gids))\n",
        "    #progress = tqdm(total=len(zipped))\n",
        "    #tracker = 0\n",
        "    for (c, g) in zip(cids, gids):\n",
        "        # Add our positive interaction\n",
        "        cell_input.append(c)\n",
        "        gene_input.append(g)\n",
        "        labels.append((df_train[(df_train.cell_id==c)&(df_train.gene_id==g)]).expression.values[0])\n",
        "        #labels.append(1)\n",
        "\n",
        "        # Sample a number of random negative interactions\n",
        "        for t in range(num_neg):\n",
        "            j = np.random.randint(len(genes))\n",
        "            #j = j if j!=32 else np.random.randint(len(genes)) # chainging to more than 1 \n",
        "            while (c, j) in zipped:\n",
        "                j = np.random.randint(len(genes))\n",
        "                #j = rv+1 if rv==0 else rv\n",
        "            #print(\"gene value: \", j, \" cell value: \", c)\n",
        "            if j!=df_test.gene_id[0]:\n",
        "                \n",
        "                cell_input.append(c)\n",
        "                gene_input.append(j)\n",
        "                #print(\"gene value: \", j, \" cell value: \", c)\n",
        "                #labels.append(0)\n",
        "                labels.append((df_train[(df_train.cell_id==c)&(df_train.gene_id==j)]).expression.values[0])\n",
        "        #progress.update(1)\n",
        "        #progress.set_description('Sampled Training Instance' + str(tracker+1)) \n",
        "        #tracker+=1\n",
        "    #progress.close()\n",
        "    return cell_input, gene_input, labels\n",
        "\n",
        "# for faster training\n",
        "def random_mini_batches(C, G, L, mini_batch_size=20):\n",
        "\n",
        "    mini_batches = []\n",
        "\n",
        "    shuffled_C, shuffled_G, shuffled_L = shuffle(C, G, L, random_state=0)\n",
        "\n",
        "    num_complete_batches = int(math.floor(len(C)/mini_batch_size))\n",
        "    for k in range(0, num_complete_batches):\n",
        "        mini_batch_C = shuffled_C[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_G = shuffled_G[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_L = shuffled_L[k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "\n",
        "        mini_batch = (mini_batch_C, mini_batch_G, mini_batch_L)\n",
        "        mini_batches.append(mini_batch)\n",
        "\n",
        "    if len(C) % mini_batch_size != 0:\n",
        "        mini_batch_C = shuffled_C[num_complete_batches * mini_batch_size: len(C)]\n",
        "        mini_batch_G = shuffled_G[num_complete_batches * mini_batch_size: len(C)]\n",
        "        mini_batch_L = shuffled_L[num_complete_batches * mini_batch_size: len(C)]\n",
        "\n",
        "        mini_batch = (mini_batch_C, mini_batch_G, mini_batch_L)\n",
        "        mini_batches.append(mini_batch)\n",
        "\n",
        "    return mini_batches"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jt-OkNr4NElH",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# evaluation\n",
        "def get_hits(k_ranked, holdout):\n",
        "    for gene in k_ranked:\n",
        "        if gene == holdout:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "def eval_rating(idx, test_expression, test_negatives, K):\n",
        "    # test_expression = test_expression_ids\n",
        "    map_gene_score = {}\n",
        "\n",
        "    \n",
        "    genes = test_negatives[idx]\n",
        "\n",
        "    \n",
        "    cell_idx = test_expression[idx][0]\n",
        "\n",
        "    \n",
        "    holdout = test_expression[idx][1]\n",
        "    print(\"Holdout: \", holdout)\n",
        "\n",
        "    \n",
        "    genes.append(holdout)\n",
        "\n",
        "    \n",
        "    predict_cell = np.full(len(genes), cell_idx, dtype='int32').reshape(-1,1)\n",
        "    print(\"Predict cell: \", predict_cell)\n",
        "    np_genes = np.array(genes).reshape(-1,1)\n",
        "    print(\"Genes: \", genes)\n",
        "\n",
        "    \n",
        "    predictions = session.run([output_layer], feed_dict={cell: predict_cell, gene: np_genes})\n",
        "    print(\"Predictions: \", predictions)\n",
        "    \n",
        "    predictions = predictions[0].flatten().tolist()\n",
        "\n",
        "    \n",
        "    for i in range(len(genes)):\n",
        "        current_gene = genes[i]\n",
        "        map_gene_score[current_gene] = predictions[i]\n",
        "\n",
        "    \n",
        "    k_ranked = heapq.nlargest(K, map_gene_score, key=map_gene_score.get)\n",
        "    print(\"K Ranked: \", k_ranked)\n",
        "\n",
        "       \n",
        "    hits = get_hits(k_ranked, holdout)\n",
        "\n",
        "    return hits\n",
        "\n",
        "# \n",
        "def evaluate(df_neg, K=10):\n",
        "\n",
        "    hits = []\n",
        "\n",
        "    test_c = df_test['cell_id'].values.tolist()\n",
        "    test_g = df_test['gene_id'].values.tolist()\n",
        "\n",
        "    test_expression_ids = list(zip(test_c, test_g))\n",
        "\n",
        "    df_neg = df_neg.drop(df_neg.columns[0], axis=1)\n",
        "    test_negatives = df_neg.values.tolist()\n",
        "    #len(test_expression)-2\n",
        "    for idx in range(len(test_expression_ids)):\n",
        "        # For each idx, call eval_one_rating\n",
        "        hitrate = eval_rating(idx, test_expression_ids, test_negatives, K)\n",
        "        hits.append(hitrate)\n",
        "\n",
        "    return hits\n",
        "\n",
        "\n",
        "def poisson_loss(y_true, y_pred):\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    f1 = tf.multiply(y_true, tf.log(tf.add(y_pred, 1e-10)))\n",
        "    nice_bound = tf.add(tf.lgamma(y_pred), 1)\n",
        "    fbound = tf.subtract(f1, nice_bound)\n",
        "    return tf.reduce_mean(tf.square(tf.subtract(y_pred, fbound)))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mDDYxAeHNUr7",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "def make_recommendation(cell_ids=None, gene_ids = None, top=None):\n",
        "    # make recommendations for all\n",
        "    df = pd.DataFrame()\n",
        "    df[\"Gene\"] = (ctr_E_df_long.gene_id).unique()\n",
        "    for cell_idx in np.sort((ctr_E_df_long.cell_id).unique()):\n",
        "        # get the genes for the given cell\n",
        "        genes = ((ctr_E_df_long[ctr_E_df_long.cell_id==cell_idx]).gene_id).values\n",
        "        #cell_ls = [cell_idx]# * len(genes)\n",
        "        # create a full gene prediction for a cell\n",
        "        predict_cell = np.full(len(genes), cell_idx, dtype='int32').reshape(-1,1)\n",
        "        np_genes = np.array(genes).reshape(-1,1)\n",
        "        \n",
        "        #run with the given session\n",
        "        predictions = session.run([output_layer], feed_dict={cell: predict_cell, gene: np_genes})\n",
        "        #print(\"Predictions: \", predictions)\n",
        "\n",
        "        predictions = predictions[0].flatten().tolist()\n",
        "        df[cell_idx] = predictions\n",
        " \n",
        "    return df\n",
        "\n",
        "# try basic k-means clustering\n",
        "def kMeans_clustering(k=10):\n",
        "    \n",
        "    \n",
        "    kmeans_labels = cluster.KMeans(n_clusters=k).fit_predict(mlp_df)\n",
        "    standard_embedding = umap.UMAP(random_state=42).fit_transform(mlp_df)\n",
        "    newdf = pd.DataFrame(standard_embedding, columns = [\"x1\", \"x2\"])\n",
        "    newdf[\"cluster\"] = kmeans_labels\n",
        "      # make the plot\n",
        "    size = 80\n",
        "    plt.figure(figsize=(16,10))\n",
        "    sc = plt.scatter(newdf['x1'], newdf['x2'], s=size, c=newdf['cluster'], edgecolors='none')\n",
        "\n",
        "    lp = lambda i: plt.plot([],color=sc.cmap(sc.norm(i)), ms=np.sqrt(size), mec=\"none\",\n",
        "                              label=\"Cluster {:g}\".format(i), ls=\"\", marker=\"o\")[0]\n",
        "    handles = [lp(i) for i in np.unique(newdf[\"cluster\"])]\n",
        "    plt.legend(handles=handles)\n",
        "    plt.xlabel(\"Umap 1\")\n",
        "    plt.ylabel(\"Umap 2\")\n",
        "    plt.show()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ucy3A3s6S4xg",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "cids, gids, df_train, df_test, df_neg, cells, genes, gene_lookup, values = process_dataset(ctr_E_df_long)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HO-14hk4Tw2n",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "23811948-3391-4f32-b853-8848b5cc148f"
      },
      "source": [
        "print(\"Unique train genes: \", len((df_train['gene_id']).drop_duplicates()))\n",
        "print(\"Unique train cells: \", len((df_train['cell_id']).drop_duplicates()))\n",
        "#print(\"Unique test genes: \", len((df_test['gene_id']).drop_duplicates()))\n",
        "#print(\"Unique test cells: \",len((df_test['cell_id']).drop_duplicates()))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique train genes:  14879\n",
            "Unique train cells:  3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fdIBDZFq6TKR",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "6f5d8ebd-0883-4b38-99cd-b8df51ace79c"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell_id</th>\n",
              "      <th>gene_id</th>\n",
              "      <th>expression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2562</td>\n",
              "      <td>10149</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2562</td>\n",
              "      <td>10150</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2562</td>\n",
              "      <td>6509</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2562</td>\n",
              "      <td>4350</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2562</td>\n",
              "      <td>7968</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cell_id  gene_id  expression\n",
              "0     2562    10149           0\n",
              "1     2562    10150           0\n",
              "2     2562     6509           0\n",
              "3     2562     4350           0\n",
              "4     2562     7968           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Va1pohlqgOz3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1298a239-d287-4735-b90a-1386a582144a"
      },
      "source": [
        "df_train.shape[0]/16"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2789812.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b-aJ-IwDn7HB"
      },
      "source": [
        "### **(3) Set Training Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_U-WWuSBVplW",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# define learning parameters\n",
        "num_neg = 4\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "latent_features = 20"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IZDtvIMtV8UF",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# get train instances\n",
        "cell_input, gene_input, labels = cids, gids, values#get_train_instances()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yrbQKH5VKfXj",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "#sum(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qwPYghEET6Co"
      },
      "source": [
        "### (4) **Build & Train MLP Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Q_VFxWKT9nV",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "26f3cff1-018c-44c6-f23e-b8c86c64509c"
      },
      "source": [
        "graph = tf.Graph() # tensorflow term for building a pipeline\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "  with graph.as_default():\n",
        "\n",
        "      # define input placeholders for cell, gene and count=label.\n",
        "      cell = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "      gene = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "      label = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "\n",
        "      # cell feature embedding\n",
        "      c_var = tf.Variable(tf.random_uniform([len(cells), 20], minval= 0), name='cell_embedding')\n",
        "      cell_embedding = tf.nn.embedding_lookup(c_var, cell) # for each cell id, return a vector of length 20\n",
        "\n",
        "      # gene feature embedding\n",
        "      g_var = tf.Variable(tf.random_uniform([len(genes), 20], minval= 0), name='gene_embedding')\n",
        "      gene_embedding = tf.nn.embedding_lookup(g_var, gene) # for each gene id, return a vector of length 20\n",
        "\n",
        "      # Flatten our cell and gene embeddings.\n",
        "      cell_embedding = tf.keras.layers.Flatten()(cell_embedding)\n",
        "      gene_embedding = tf.keras.layers.Flatten()(gene_embedding)\n",
        "\n",
        "      # concatenate the two embedding vectors\n",
        "      concatenated = tf.keras.layers.concatenate([cell_embedding, gene_embedding])\n",
        "\n",
        "      \n",
        "      # add a first dropout layer.\n",
        "      dropout = tf.keras.layers.Dropout(0.2)(concatenated)\n",
        "\n",
        "      # add four hidden layers along with batch\n",
        "      # normalization and dropouts. use relu as the activation function.\n",
        "      layer_1 = tf.keras.layers.Dense(64, activation='relu', name='layer1')(dropout)\n",
        "      batch_norm1 = tf.keras.layers.BatchNormalization(name='batch_norm1')(layer_1)\n",
        "      dropout1 = tf.keras.layers.Dropout(0.2, name='dropout1')(batch_norm1)\n",
        "\n",
        "      layer_2 = tf.keras.layers.Dense(32, activation='relu', name='layer2')(layer_1)\n",
        "      batch_norm2 = tf.keras.layers.BatchNormalization(name='batch_norm1')(layer_2)\n",
        "      dropout2 = tf.keras.layers.Dropout(0.2, name='dropout1')(batch_norm2)\n",
        "\n",
        "      layer_3 = tf.keras.layers.Dense(16, activation='relu', name='layer3')(layer_2)\n",
        "      layer_4 = tf.keras.layers.Dense(8, activation='exponential', name='layer4')(layer_3) # make linear\n",
        "\n",
        "      # final single neuron output layer.\n",
        "      output_layer = tf.keras.layers.Dense(1,\n",
        "              kernel_initializer=\"lecun_uniform\",\n",
        "              name='output_layer')(layer_4)\n",
        "\n",
        "      # our loss function as mse.\n",
        "      labels = tf.cast(label, tf.float32)\n",
        "      #print(labels)\n",
        "      logits = output_layer\n",
        "      #tf.print(logits)\n",
        "      #loss =  poisson_loss(labels, logits) #tf.nn.log_poisson_loss(labels, logits)\n",
        "      loss = poisson_loss(labels, logits)\n",
        "      #print(loss)\n",
        "\n",
        "      # train using the Adam optimizer to minimize loss.\n",
        "      opt = tf.train.AdamOptimizer(learning_rate = learning_rate, epsilon=1)\n",
        "      step = opt.minimize(loss)\n",
        "\n",
        "      # initialize all tensorflow variables.\n",
        "      init = tf.global_variables_initializer()\n",
        "\n",
        "session = tf.Session(config=None, graph=graph)\n",
        "session.run(init)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a-pUtYfRV21l",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# for epoch in range(epochs):\n",
        "\n",
        "#     # Get our training input.\n",
        "#     cell_input, gene_input, labels = cids, gids, values  #get_train_instances()\n",
        "\n",
        "#     # Generate a list of minibatches.\n",
        "#     minibatches = random_mini_batches(cell_input, gene_input, labels)\n",
        "\n",
        "#     # This has noting to do with tensorflow but gives\n",
        "#     # us a nice progress bar for the training\n",
        "#     progress = tqdm(total=len(minibatches))\n",
        "\n",
        "#     # Loop over each batch and feed our cells, genes and labels\n",
        "#     # into our graph. \n",
        "#     for minibatch in minibatches:\n",
        "#         feed_dict = {cell: np.array(minibatch[0]).reshape(-1,1),\n",
        "#                     gene: np.array(minibatch[1]).reshape(-1,1),\n",
        "#                     label: np.array(minibatch[2]).reshape(-1,1)}\n",
        "   \n",
        "#         # Execute the graph.\n",
        "#         _, l = session.run([step, loss], feed_dict)\n",
        "#         # Update the progress\n",
        "#         progress.update(1)\n",
        "#         progress.set_description('Epoch: %d - Loss: %.8f' % (epoch+1, l))\n",
        "\n",
        "#     progress.close()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "chDk0bQJeFXd",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# mlp_df = make_recommendation()\n",
        "# #mlp_df.drop('Gene', axis=1, inplace=True)\n",
        "# mlp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HfNnaRTjg8MY",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# # try basic clustering\n",
        "# kMeans_clustering()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JOeD4NHFlFTN"
      },
      "source": [
        "### **(5) Build & Train GMF Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZQzTybLklIHI",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "6ee071c0-80e7-49c2-c1cb-0a614c421b77"
      },
      "source": [
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default():\n",
        "\n",
        "    cell = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "    gene = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "    label = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "\n",
        "    \n",
        "    c_var = tf.Variable(tf.random_uniform([len(cells), latent_features],\n",
        "                                         minval =0.0), name='cell_embedding')\n",
        "    cell_embedding = tf.nn.embedding_lookup(c_var, cell)\n",
        "\n",
        "\n",
        "    g_var = tf.Variable(tf.random_uniform([len(genes), latent_features],\n",
        "                                         minval=0.0), name='gene_embedding')\n",
        "    gene_embedding = tf.nn.embedding_lookup(g_var, gene)\n",
        "    \n",
        "    # flatten the embeddings \n",
        "    cell_embedding = tf.keras.layers.Flatten()(cell_embedding)\n",
        "    gene_embedding = tf.keras.layers.Flatten()(gene_embedding)\n",
        "\n",
        "    # multiplying our cell and gene latent space vectors together \n",
        "    prediction_matrix = tf.multiply(cell_embedding, gene_embedding)\n",
        "\n",
        "    \n",
        "    output_layer = tf.keras.layers.Dense(1, \n",
        "            kernel_initializer=\"lecun_uniform\",\n",
        "            name='output_layer')(prediction_matrix)\n",
        "\n",
        "    # loss function as mse. \n",
        "    labels = tf.cast(label, tf.float32)\n",
        "    loss = tf.reduce_mean(tf.square(tf.subtract(labels, output_layer)))\n",
        "    \n",
        "    # using the Adam optimizer to minimize loss.\n",
        "    opt = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
        "    step = opt.minimize(loss)\n",
        "\n",
        "    # initialize all tensorflow variables.\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "session = tf.Session(config=None, graph=graph)\n",
        "session.run(init)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mOQohQDylMiv",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# for epoch in range(epochs):\n",
        "\n",
        "#     # Get our training input.\n",
        "#     cell_input, gene_input, labels = get_train_instances()\n",
        "\n",
        "#     # Generate a list of minibatches.\n",
        "#     minibatches = random_mini_batches(cell_input, gene_input, labels)\n",
        "\n",
        "#     # This has noting to do with tensorflow but gives\n",
        "#     # us a nice progress bar for the training\n",
        "#     progress = tqdm(total=len(minibatches))\n",
        "\n",
        "#     # Loop over each batch and feed our cells, genes and labels\n",
        "#     # into our graph. \n",
        "#     for minibatch in minibatches:\n",
        "#         feed_dict = {cell: np.array(minibatch[0]).reshape(-1,1),\n",
        "#                     gene: np.array(minibatch[1]).reshape(-1,1),\n",
        "#                     label: np.array(minibatch[2]).reshape(-1,1)}\n",
        "   \n",
        "#         # Execute the graph.\n",
        "#         _, l = session.run([step, loss], feed_dict)\n",
        "\n",
        "#         # Update the progress\n",
        "#         progress.update(1)\n",
        "#         progress.set_description('Epoch: %d - Loss: %.3f' % (epoch+1, l))\n",
        "\n",
        "#     progress.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K67wuFY8lU_c",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# mlp_df = make_recommendation()\n",
        "# mlp_df.drop('Gene', axis=1, inplace=True)\n",
        "# mlp_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VcRXldjylV6t",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "# # try basic clustering\n",
        "# kMeans_clustering()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q4RXauN3lWqX"
      },
      "source": [
        "### **(6) Build & Train Combined NeuMF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wxpB2gGOlalr",
        "trusted": true,
        "colab": {}
      },
      "source": [
        "graph = tf.Graph()\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "  with graph.as_default():\n",
        "\n",
        "      cell = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "      gene = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "      label = tf.placeholder(tf.int32, shape=(None, 1))\n",
        "\n",
        "      \n",
        "      mlp_c_var = tf.Variable(tf.random_uniform([len(cells), latent_features], minval=0), name='mlp_cell_embedding')\n",
        "      mlp_cell_embedding = tf.nn.embedding_lookup(mlp_c_var, cell)\n",
        "\n",
        "      \n",
        "      mlp_g_var = tf.Variable(tf.random_uniform([len(genes), latent_features], minval=0), name='mlp_gene_embedding')\n",
        "      mlp_gene_embedding = tf.nn.embedding_lookup(mlp_g_var, gene)\n",
        "\n",
        "      \n",
        "      gmf_c_var = tf.Variable(tf.random_uniform([len(cells), latent_features], minval=0), name='gmf_cell_embedding')\n",
        "      gmf_cell_embedding = tf.nn.embedding_lookup(gmf_c_var, cell)\n",
        "\n",
        "      # gene embedding for GMF\n",
        "      gmf_g_var = tf.Variable(tf.random_uniform([len(genes), latent_features], minval=0), name='gmf_item_embedding')\n",
        "      gmf_gene_embedding = tf.nn.embedding_lookup(gmf_g_var, gene)\n",
        "\n",
        "      # flatten gmf embedding\n",
        "      gmf_cell_embed = tf.keras.layers.Flatten()(gmf_cell_embedding)\n",
        "      gmf_gene_embed = tf.keras.layers.Flatten()(gmf_gene_embedding)\n",
        "      gmf_matrix = tf.multiply(gmf_cell_embed, gmf_gene_embed)\n",
        "\n",
        "      # flatten mlp embedding\n",
        "      mlp_cell_embed = tf.keras.layers.Flatten()(mlp_cell_embedding)\n",
        "      mlp_gene_embed = tf.keras.layers.Flatten()(mlp_gene_embedding)\n",
        "      mlp_concat = tf.keras.layers.concatenate([mlp_cell_embed, mlp_gene_embed])\n",
        "\n",
        "      mlp_dropout = tf.keras.layers.Dropout(0.2)(mlp_concat)\n",
        "\n",
        "      mlp_layer_1 = tf.keras.layers.Dense(64, activation='relu', name='layer1')(mlp_dropout)\n",
        "      mlp_batch_norm1 = tf.keras.layers.BatchNormalization(name='batch_norm1')(mlp_layer_1)\n",
        "      mlp_dropout1 = tf.keras.layers.Dropout(0.2, name='dropout1')(mlp_batch_norm1)\n",
        "\n",
        "      mlp_layer_2 = tf.keras.layers.Dense(32, activation='relu', name='layer2')(mlp_dropout1)\n",
        "      mlp_batch_norm2 = tf.keras.layers.BatchNormalization(name='batch_norm1')(mlp_layer_2)\n",
        "      mlp_dropout2 = tf.keras.layers.Dropout(0.2, name='dropout1')(mlp_batch_norm2)\n",
        "\n",
        "      mlp_layer_3 = tf.keras.layers.Dense(16, activation='relu', name='layer3')(mlp_dropout2)\n",
        "      mlp_layer_4 = tf.keras.layers.Dense(8, activation='exponential', name='layer4')(mlp_layer_3)\n",
        "\n",
        "      # We merge the two networks together\n",
        "      merged_vector = tf.keras.layers.concatenate([gmf_matrix, mlp_layer_4])\n",
        "\n",
        "      # Our final single neuron output layer. \n",
        "      output_layer = tf.keras.layers.Dense(1,\n",
        "              kernel_initializer=\"lecun_uniform\",\n",
        "              name='output_layer')(merged_vector)\n",
        "\n",
        "      # Our loss function as mse. \n",
        "      labels = tf.cast(label, tf.float32)\n",
        "      loss = tf.reduce_mean(tf.square(tf.subtract(\n",
        "                  labels,\n",
        "                  output_layer)))\n",
        "      #loss = poisson_loss(labels, output_layer)\n",
        "\n",
        "      # Train using the Adam optimizer to minimize our loss.\n",
        "      opt = tf.train.AdamOptimizer(learning_rate = learning_rate, epsilon=1)\n",
        "      step = opt.minimize(loss)\n",
        "\n",
        "      # Initialize all tensorflow variables.\n",
        "      init = tf.global_variables_initializer()\n",
        "\n",
        "\n",
        "session = tf.Session(config=None, graph=graph)\n",
        "session.run(init)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9BNFsRL2lgkw",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3132f603-4670-4daa-a606-36fcc3e0294d"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "    # Get our training input.\n",
        "    cell_input, gene_input, labels = cids, gids, values #get_train_instances()\n",
        "\n",
        "    # Generate a list of minibatches.\n",
        "    minibatches = random_mini_batches(cell_input, gene_input, labels, batch_size)\n",
        "\n",
        "    # This has noting to do with tensorflow but gives\n",
        "    # us a nice progress bar for the training\n",
        "    progress = tqdm(total=len(minibatches))\n",
        "\n",
        "    # Loop over each batch and feed our cells, genes and labels\n",
        "    # into our graph. \n",
        "    for minibatch in minibatches:\n",
        "        feed_dict = {cell: np.array(minibatch[0]).reshape(-1,1),\n",
        "                    gene: np.array(minibatch[1]).reshape(-1,1),\n",
        "                    label: np.array(minibatch[2]).reshape(-1,1)}\n",
        "   \n",
        "        # Execute the graph.\n",
        "        _, l = session.run([step, loss], feed_dict)\n",
        "        # Update the progress\n",
        "        progress.update(1)\n",
        "        progress.set_description('Epoch: %d - Loss: %.3f' % (epoch+1, l))\n",
        "\n",
        "    progress.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 - Loss: 2.192:   4%|â–         | 14608/348727 [01:53<42:24, 131.32it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-y3T7VEF07gY",
        "trusted": false,
        "colab": {},
        "outputId": "85a82d8f-d605-4163-cd31-776a2830f7fc"
      },
      "source": [
        "mlp_df = make_recommendation()\n",
        "#mlp_df.drop('Gene', axis=1, inplace=True) #uncomment to cluster but comment out when writing out to csv file.\n",
        "mlp_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gene</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>2990</th>\n",
              "      <th>2991</th>\n",
              "      <th>2992</th>\n",
              "      <th>2993</th>\n",
              "      <th>2994</th>\n",
              "      <th>2995</th>\n",
              "      <th>2996</th>\n",
              "      <th>2997</th>\n",
              "      <th>2998</th>\n",
              "      <th>2999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10149</td>\n",
              "      <td>-0.109607</td>\n",
              "      <td>-0.090646</td>\n",
              "      <td>0.063390</td>\n",
              "      <td>0.171236</td>\n",
              "      <td>-0.021054</td>\n",
              "      <td>0.015610</td>\n",
              "      <td>-0.202013</td>\n",
              "      <td>-0.048542</td>\n",
              "      <td>0.006768</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.213967</td>\n",
              "      <td>0.355284</td>\n",
              "      <td>0.090094</td>\n",
              "      <td>0.090131</td>\n",
              "      <td>-0.116367</td>\n",
              "      <td>0.037318</td>\n",
              "      <td>-0.330887</td>\n",
              "      <td>-0.049213</td>\n",
              "      <td>0.101271</td>\n",
              "      <td>-0.095069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10150</td>\n",
              "      <td>0.221052</td>\n",
              "      <td>0.318315</td>\n",
              "      <td>-0.143035</td>\n",
              "      <td>-0.169982</td>\n",
              "      <td>-0.119768</td>\n",
              "      <td>-0.020927</td>\n",
              "      <td>0.063414</td>\n",
              "      <td>0.054166</td>\n",
              "      <td>0.097017</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.083689</td>\n",
              "      <td>0.228022</td>\n",
              "      <td>-0.054430</td>\n",
              "      <td>-0.043864</td>\n",
              "      <td>0.115597</td>\n",
              "      <td>-0.146019</td>\n",
              "      <td>0.044048</td>\n",
              "      <td>-0.021509</td>\n",
              "      <td>0.179426</td>\n",
              "      <td>-0.096212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6509</td>\n",
              "      <td>0.495100</td>\n",
              "      <td>0.355280</td>\n",
              "      <td>0.101783</td>\n",
              "      <td>0.384724</td>\n",
              "      <td>0.245239</td>\n",
              "      <td>0.067779</td>\n",
              "      <td>0.406297</td>\n",
              "      <td>0.140447</td>\n",
              "      <td>0.352215</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138778</td>\n",
              "      <td>0.729267</td>\n",
              "      <td>0.261653</td>\n",
              "      <td>0.111202</td>\n",
              "      <td>0.397685</td>\n",
              "      <td>-0.151987</td>\n",
              "      <td>0.176280</td>\n",
              "      <td>0.235564</td>\n",
              "      <td>0.308875</td>\n",
              "      <td>0.183897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4350</td>\n",
              "      <td>-0.255056</td>\n",
              "      <td>-0.256833</td>\n",
              "      <td>-0.098441</td>\n",
              "      <td>-0.424606</td>\n",
              "      <td>-0.576692</td>\n",
              "      <td>-0.315842</td>\n",
              "      <td>-0.154522</td>\n",
              "      <td>-0.239920</td>\n",
              "      <td>-0.394753</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.144013</td>\n",
              "      <td>-0.084084</td>\n",
              "      <td>-0.297610</td>\n",
              "      <td>-0.247184</td>\n",
              "      <td>-0.205889</td>\n",
              "      <td>-0.411532</td>\n",
              "      <td>-0.209749</td>\n",
              "      <td>-0.319764</td>\n",
              "      <td>0.030271</td>\n",
              "      <td>-0.363680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7968</td>\n",
              "      <td>0.528641</td>\n",
              "      <td>0.730244</td>\n",
              "      <td>0.356902</td>\n",
              "      <td>0.284494</td>\n",
              "      <td>0.372609</td>\n",
              "      <td>0.321652</td>\n",
              "      <td>0.480853</td>\n",
              "      <td>0.193765</td>\n",
              "      <td>0.215211</td>\n",
              "      <td>...</td>\n",
              "      <td>0.181251</td>\n",
              "      <td>0.635374</td>\n",
              "      <td>0.590135</td>\n",
              "      <td>0.334801</td>\n",
              "      <td>0.439470</td>\n",
              "      <td>0.231032</td>\n",
              "      <td>0.185807</td>\n",
              "      <td>0.427348</td>\n",
              "      <td>0.596540</td>\n",
              "      <td>0.290461</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 3001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Gene         0         1         2         3         4         5  \\\n",
              "0  10149 -0.109607 -0.090646  0.063390  0.171236 -0.021054  0.015610   \n",
              "1  10150  0.221052  0.318315 -0.143035 -0.169982 -0.119768 -0.020927   \n",
              "2   6509  0.495100  0.355280  0.101783  0.384724  0.245239  0.067779   \n",
              "3   4350 -0.255056 -0.256833 -0.098441 -0.424606 -0.576692 -0.315842   \n",
              "4   7968  0.528641  0.730244  0.356902  0.284494  0.372609  0.321652   \n",
              "\n",
              "          6         7         8    ...         2990      2991      2992  \\\n",
              "0 -0.202013 -0.048542  0.006768    ...    -0.213967  0.355284  0.090094   \n",
              "1  0.063414  0.054166  0.097017    ...    -0.083689  0.228022 -0.054430   \n",
              "2  0.406297  0.140447  0.352215    ...     0.138778  0.729267  0.261653   \n",
              "3 -0.154522 -0.239920 -0.394753    ...    -0.144013 -0.084084 -0.297610   \n",
              "4  0.480853  0.193765  0.215211    ...     0.181251  0.635374  0.590135   \n",
              "\n",
              "       2993      2994      2995      2996      2997      2998      2999  \n",
              "0  0.090131 -0.116367  0.037318 -0.330887 -0.049213  0.101271 -0.095069  \n",
              "1 -0.043864  0.115597 -0.146019  0.044048 -0.021509  0.179426 -0.096212  \n",
              "2  0.111202  0.397685 -0.151987  0.176280  0.235564  0.308875  0.183897  \n",
              "3 -0.247184 -0.205889 -0.411532 -0.209749 -0.319764  0.030271 -0.363680  \n",
              "4  0.334801  0.439470  0.231032  0.185807  0.427348  0.596540  0.290461  \n",
              "\n",
              "[5 rows x 3001 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jwBNqgmo-K6C",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "# try basic clustering\n",
        "#kMeans_clustering(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HNiDwpJRpy2Z"
      },
      "source": [
        "### **(7) Save Dense Matrix to File**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m_biCN_RpwPr",
        "trusted": false,
        "colab": {}
      },
      "source": [
        "mlp_df.to_csv(\"ctrl_dense_shortAll3.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": false,
        "id": "GlHOronzgO0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}