{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "original_dim = 28*28\n",
    "latent_dim = 2\n",
    "intermediate_dim = 256\n",
    "nb_epoch = 5\n",
    "epsilon_std = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoding (Dense)                (None, 256)          200960      input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mean (Dense)                    (None, 2)            514         encoding[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "log-variance (Dense)            (None, 2)            514         encoding[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           mean[0][0]                       \n",
      "                                                                 log-variance[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 201,988\n",
      "Trainable params: 201,988\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the input image\n",
    "x = Input(shape=(original_dim,), name=\"input\")\n",
    "h = Dense(intermediate_dim, activation='relu', name=\"encoding\")(x)\n",
    "# using a VAE with mean and variance specification been that of the normal\n",
    "z_mean = Dense(latent_dim, name=\"mean\")(h)\n",
    "z_log_var = Dense(latent_dim, name=\"log-variance\")(h)\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "# encoder\n",
    "encoder = Model(x, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "decoder_h (Dense)            (None, 256)               768       \n",
      "_________________________________________________________________\n",
      "flat_decoded (Dense)         (None, 784)               201488    \n",
      "=================================================================\n",
      "Total params: 202,256\n",
      "Trainable params: 202,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the decoder\n",
    "input_decoder = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
    "decoder_h = Dense(intermediate_dim, activation='relu',\n",
    "name=\"decoder_h\")(input_decoder)\n",
    "x_decoded = Dense(original_dim, activation='sigmoid',\n",
    "name=\"flat_decoded\")(decoder_h)\n",
    "decoder = Model(input_decoder, x_decoded, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 201988    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               202256    \n",
      "=================================================================\n",
      "Total params: 404,244\n",
      "Trainable params: 404,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# combining the model\n",
    "output_combined = decoder(encoder(x)[2])\n",
    "vae = Model(x, output_combined)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sixtusdakurah/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 201988    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               202256    \n",
      "=================================================================\n",
      "Total params: 404,244\n",
      "Trainable params: 404,244\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def vae_loss(x: tf.Tensor, x_decoded_mean: tf.Tensor, z_log_var=z_log_var, z_mean=z_mean, original_dim=original_dim):\n",
    "    xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x145308898>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(x_train[0], (28,28))\n",
    "#curr_lbl = train_labels[0]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "#plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(x_test[0], (28,28))\n",
    "#curr_lbl = test_labels[0]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "#plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sixtusdakurah/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "# this will not run on low memory ... run the notebook on google colab\n",
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        epochs=nb_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
